{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malinphy/LangChain/blob/main/LangChain_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KK_2_ti94Yae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LynUObK34ZTx",
        "outputId": "328a6346-5d98-423b-8e84-bd4fce5ba12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj6cbR0JBTCP"
      },
      "source": [
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install google-search-results -q\n",
        "import os \n",
        "os.environ[\"OPENAI_API_KEY\"] = \n",
        "os.environ['SERPAPI_API_KEY'] = "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UweeQOY_BeGQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)"
      ],
      "metadata": {
        "id": "nWDCgDzqBgFO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'What are 5 vacation destinations for someone who like to eat pasta'\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK8aZtCeBht3",
        "outputId": "216ef568-df83-4081-b784-6f43c9b26a1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Rome, Italy\n",
            "2. Naples, Italy\n",
            "3. Amalfi Coast, Italy\n",
            "4. Piedmont, Italy\n",
            "5. Bologna, Italy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables = ['food'],\n",
        "    template = 'what are 5 vacation destinations for someone who like to eat {food}'\n",
        "    )"
      ],
      "metadata": {
        "id": "KQ6tZPcFBjHa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(food = 'dessert'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMe7RXHdBlbW",
        "outputId": "1a9703da-8e73-42e2-a173-4e4357a4c1be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what are 5 vacation destinations for someone who like to eat dessert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(food= 'kebab')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKX7-jcWBneH",
        "outputId": "eac11b87-556d-4ce0-8204-8de26ac095ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Istanbul, Turkey \n",
            "2. Kabul, Afghanistan \n",
            "3. Tehran, Iran \n",
            "4. Dubai, UAE \n",
            "5. Amman, Jordan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "z5M12TgABpOY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = ['food'],\n",
        "    template = 'What are 5 vacation destinations for someone who likes to eat {food}'\n",
        "    )"
      ],
      "metadata": {
        "id": "0gc0lGo9BqlI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm = llm, prompt = prompt)"
      ],
      "metadata": {
        "id": "-Uta4QSSBsEP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run('fruit'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drwZw8iwBtdP",
        "outputId": "a5b654dd-73f3-457f-ad9c-6bf989e8b792"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Hawaii - With excellent climate and fast access to fresh local produce, Hawaii is renowned for its exotic fruit and delicious cuisine.\n",
            "\n",
            "2. Seychelles - With an abundance of tropical fruit, Seychelles has a diverse variety of fruit that can be enjoyed while on vacation.\n",
            "\n",
            "3. Thailand - A hotspot for adventurous foodies, Thailand offers endless opportunities to sample some of its delicious and flavourful fruits.\n",
            "\n",
            "4. Costa Rica - Costa Rica is a great option for travelers looking for a tropical paradise with a large selection of exotic fruit.\n",
            "\n",
            "5. Mexico - From traditional favorites like mango and papaya to lesser-known fruits like guanabana and mamey, Mexico offers plenty of delicious fruit to excite the palate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "tbpcIyNkBvSP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)\n",
        "tools = load_tools(['serpapi', 'llm-math'], llm = llm)"
      ],
      "metadata": {
        "id": "wXaEJcbLBw4X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent = 'zero-shot-react-description', verbose = True)"
      ],
      "metadata": {
        "id": "Co-bSoyECGhg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('who is the current leader of Japan? What is the largest prime that is smaller than their age?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "wmkeEORwC2vp",
        "outputId": "90407344-eba0-431a-b915-207258883467"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should look up their age and then find out the prime.\n",
            "Action: Search\n",
            "Action Input: current age of leader of Japan\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m65 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can use the calculator to find the largest prime\n",
            "Action: Calculator\n",
            "Action Input: 65\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 65\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Shinzo Abe is the current leader of Japan, and the largest prime that is smaller than his age is 65.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shinzo Abe is the current leader of Japan, and the largest prime that is smaller than his age is 65.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory: Add State to chains and agents"
      ],
      "metadata": {
        "id": "O35nGx3eDoA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain"
      ],
      "metadata": {
        "id": "OdQPjEHODgNS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)\n",
        "conversation = ConversationChain(llm = llm, verbose = True)"
      ],
      "metadata": {
        "id": "gFaa-PGmFdR5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = 'Hi there')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "A4SWVeu2FtYH",
        "outputId": "eec8d192-2782-4c7f-cc95-7aa60feb5049"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello there, how can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = 'The weather is terrible today and I am feeling terrible.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "IZJbcbtbFy5w",
        "outputId": "b46352cc-4b3a-4038-c370-92b4bab0e268"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there\n",
            "AI:  Hello there, how can I help you today?\n",
            "Human: The weather is terrible today and I am feeling terrible.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Oh no, I'm sorry to hear that! It looks like the weather outside is cloudy and rainy. But I'm sure it will get better soon. Is there anything else I can help you with?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = 'I hope, you can give me advice to feel better.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "u1SvM_o3F6xK",
        "outputId": "ab578ee4-13dd-4ed9-9b98-30ba90add4b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there\n",
            "AI:  Hello there, how can I help you today?\n",
            "Human: The weather is terrible today and I am feeling terrible.\n",
            "AI:  Oh no, I'm sorry to hear that! It looks like the weather outside is cloudy and rainy. But I'm sure it will get better soon. Is there anything else I can help you with?\n",
            "Human: I hope, you can give me advice to feel better.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Well, feeling down can be tough and everyone handles it differently. It might help to take a break from whatever you are doing and find something that makes you feel good. Talk to a friend, read a book, or watch a movie. Doing something to get your mind off your current mood can help. Is there anything else I can help you with?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents\n"
      ],
      "metadata": {
        "id": "KC0DGd0P0BzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "9rJ_7PznHKTq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0)"
      ],
      "metadata": {
        "id": "EfzwoiElHQIq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_names = ['serpapi']\n",
        "tools = load_tools(tool_names)"
      ],
      "metadata": {
        "id": "ulCYoiHRHUWC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent = 'zero-shot-react-description', verbose = True)\n"
      ],
      "metadata": {
        "id": "hb41nP_R1B4z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('What is LangChain')"
      ],
      "metadata": {
        "id": "CjKyP_au1LQS",
        "outputId": "8d9d4e7f-4a6e-4fb1-f28e-27772944f0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should research what LangChain is\n",
            "Action: Search\n",
            "Action Input: \"LangChain\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should read more about LangChain\n",
            "Action: Search\n",
            "Action Input: \"LangChain overview\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAt its core, LangChain is a framework built around LLMs. We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more. The core ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know what LangChain is\n",
            "Final Answer: LangChain is a framework built around LLMs that can be used for chatbots, Generative Question-Answering (GQA), summarization, and more.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is a framework built around LLMs that can be used for chatbots, Generative Question-Answering (GQA), summarization, and more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('Who is the CEO of Coca-Cola')"
      ],
      "metadata": {
        "id": "iCjdwkmm1OSO",
        "outputId": "76a1d2ae-1c5c-4b77-a310-9753da13a68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out who the CEO of Coca-Cola is\n",
            "Action: Search\n",
            "Action Input: \"Coca-Cola CEO\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mJames Quincey\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: James Quincey is the CEO of Coca-Cola.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'James Quincey is the CEO of Coca-Cola.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask Question on your custom(or piravite)File + ChatGPT"
      ],
      "metadata": {
        "id": "2PuQN5OJ2D1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-magic -q\n",
        "!pip install unstructured -q\n",
        "!pip install chromadb -q"
      ],
      "metadata": {
        "id": "aRJhFbLf2-uN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma \n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain import VectorDBQA\n",
        "import magic \n",
        "import os \n",
        "import nltk"
      ],
      "metadata": {
        "id": "8JtEJMTg1zJZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('drive/MyDrive/transfer/p_graham_essays')"
      ],
      "metadata": {
        "id": "dbMl4J9t2vpv",
        "outputId": "595b07db-b080-481f-9fff-07f5f31371a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['p1.txt', 'p2.txt', 'p3.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('drive/MyDrive/transfer/p_graham_essays/', glob = '**/*.txt')"
      ],
      "metadata": {
        "id": "fWu1O2Jx4ULm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "9jLITCyz5Bps"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "IarN7WjN5G5c",
        "outputId": "42d64b0e-e8a6-40ca-ee40-615a9adc8902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='September 2017\\n\\nThe most valuable insights are both general and surprising.\\n\\nF&nbsp;=&nbsp;ma for example. But general and surprising is a hard\\n\\ncombination to achieve. That territory tends to be picked\\n\\nclean, precisely because those insights are so valuable.\\n\\nOrdinarily, the best that people can do is one without the\\n\\nother: either surprising without being general (e.g.\\n\\ngossip), or general without being surprising (e.g.\\n\\nplatitudes).\\n\\nWhere things get interesting is the moderately valuable\\n\\ninsights.  You get those from small additions of whichever\\n\\nquality was missing.  The more common case is a small\\n\\naddition of generality: a piece of gossip that\\'s more than\\n\\njust gossip, because it teaches something interesting about\\n\\nthe world. But another less common approach is to focus on\\n\\nthe most general ideas and see if you can find something new\\n\\nto say about them. Because these start out so general, you\\n\\nonly need a small delta of novelty to produce a useful\\n\\ninsight.\\n\\nA small delta of novelty is all you\\'ll be able to get most\\n\\nof the time. Which means if you take this route your ideas\\n\\nwill seem a lot like ones that already exist. Sometimes\\n\\nyou\\'ll find you\\'ve merely rediscovered an idea that did\\n\\nalready exist.  But don\\'t be discouraged.  Remember the huge\\n\\nmultiplier that kicks in when you do manage to think of\\n\\nsomething even a little new.\\n\\nCorollary: the more general the ideas you\\'re talking about,\\n\\nthe less you should worry about repeating yourself.  If you\\n\\nwrite enough, it\\'s inevitable you will.  Your brain is much\\n\\nthe same from year to year and so are the stimuli that hit\\n\\nit. I feel slightly bad when I find I\\'ve said something\\n\\nclose to what I\\'ve said before, as if I were plagiarizing\\n\\nmyself. But rationally one shouldn\\'t.  You won\\'t say\\n\\nsomething exactly the same way the second time, and that\\n\\nvariation increases the chance you\\'ll get that tiny but\\n\\ncritical delta of novelty.\\n\\nAnd of course, ideas beget ideas.  (That sounds familiar.)\\n\\nAn idea with a small amount of novelty could lead to one\\n\\nwith more. But only if you keep going. So it\\'s doubly\\n\\nimportant not to let yourself be discouraged by people who\\n\\nsay there\\'s not much new about something you\\'ve discovered.\\n\\n\"Not much new\" is a real achievement when you\\'re talking\\n\\nabout the most general ideas. Maybe if you keep going,\\n\\nyou\\'ll discover more.\\n\\nIt\\'s not true that there\\'s nothing new under the sun.  There\\n\\nare some domains where there\\'s almost nothing new.  But\\n\\nthere\\'s a big difference between nothing and almost nothing,\\n\\nwhen it\\'s multiplied by the area under the sun.\\n\\n<b>Thanks</b> to Sam Altman, Patrick Collison, and Jessica\\n\\nLivingston for reading drafts of this.', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)"
      ],
      "metadata": {
        "id": "UTsDS_sa6MAE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "pr4jYioR6i0u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "kCif79q66n-b",
        "outputId": "302d82a1-19cc-4754-8a4e-1b9681c892d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"September 2017\\n\\nThe most valuable insights are both general and surprising.\\n\\nF&nbsp;=&nbsp;ma for example. But general and surprising is a hard\\n\\ncombination to achieve. That territory tends to be picked\\n\\nclean, precisely because those insights are so valuable.\\n\\nOrdinarily, the best that people can do is one without the\\n\\nother: either surprising without being general (e.g.\\n\\ngossip), or general without being surprising (e.g.\\n\\nplatitudes).\\n\\nWhere things get interesting is the moderately valuable\\n\\ninsights.  You get those from small additions of whichever\\n\\nquality was missing.  The more common case is a small\\n\\naddition of generality: a piece of gossip that's more than\\n\\njust gossip, because it teaches something interesting about\\n\\nthe world. But another less common approach is to focus on\\n\\nthe most general ideas and see if you can find something new\\n\\nto say about them. Because these start out so general, you\\n\\nonly need a small delta of novelty to produce a useful\\n\\ninsight.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              " Document(page_content=\"A small delta of novelty is all you'll be able to get most\\n\\nof the time. Which means if you take this route your ideas\\n\\nwill seem a lot like ones that already exist. Sometimes\\n\\nyou'll find you've merely rediscovered an idea that did\\n\\nalready exist.  But don't be discouraged.  Remember the huge\\n\\nmultiplier that kicks in when you do manage to think of\\n\\nsomething even a little new.\\n\\nCorollary: the more general the ideas you're talking about,\\n\\nthe less you should worry about repeating yourself.  If you\\n\\nwrite enough, it's inevitable you will.  Your brain is much\\n\\nthe same from year to year and so are the stimuli that hit\\n\\nit. I feel slightly bad when I find I've said something\\n\\nclose to what I've said before, as if I were plagiarizing\\n\\nmyself. But rationally one shouldn't.  You won't say\\n\\nsomething exactly the same way the second time, and that\\n\\nvariation increases the chance you'll get that tiny but\\n\\ncritical delta of novelty.\\n\\nAnd of course, ideas beget ideas.  (That sounds familiar.)\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              " Document(page_content='An idea with a small amount of novelty could lead to one\\n\\nwith more. But only if you keep going. So it\\'s doubly\\n\\nimportant not to let yourself be discouraged by people who\\n\\nsay there\\'s not much new about something you\\'ve discovered.\\n\\n\"Not much new\" is a real achievement when you\\'re talking\\n\\nabout the most general ideas. Maybe if you keep going,\\n\\nyou\\'ll discover more.\\n\\nIt\\'s not true that there\\'s nothing new under the sun.  There\\n\\nare some domains where there\\'s almost nothing new.  But\\n\\nthere\\'s a big difference between nothing and almost nothing,\\n\\nwhen it\\'s multiplied by the area under the sun.\\n\\n<b>Thanks</b> to Sam Altman, Patrick Collison, and Jessica\\n\\nLivingston for reading drafts of this.', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              " Document(page_content=\"January 2017\\n\\nPeople who are powerful but uncharismatic will tend to be disliked.\\nTheir power makes them a target for criticism that they don't have\\nthe charisma to disarm. That was Hillary Clinton's problem. It also\\ntends to be a problem for any CEO who is more of a builder than a\\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\\nthe best person for the job.\\n\\nI don't think there is any solution to this problem. It's human\\nnature. The best we can do is to recognize that it's happening, and\\nto understand that being a magnet for criticism is sometimes a sign\\nnot that someone is the wrong person for a job, but that they're\\nthe right one.\\nJanuary 2017\\n\\nBecause biographies of famous scientists tend to \\nedit out their mistakes, we underestimate the \\ndegree of risk they were willing to take.\\nAnd because anything a famous scientist did that\\nwasn't a mistake has probably now become the\\nconventional wisdom, those choices don't\\nseem risky either.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              " Document(page_content='Biographies of Newton, for example, understandably focus\\nmore on physics than alchemy or theology.\\nThe impression we get is that his unerring judgment\\nled him straight to truths no one else had noticed.\\nHow to explain all the time he spent on alchemy\\nand theology?  Well, smart people are often kind of\\ncrazy.\\n\\nBut maybe there is a simpler explanation. Maybe\\nthe smartness and the craziness were not as separate\\nas we think. Physics seems to us a promising thing\\nto work on, and alchemy and theology obvious wastes\\nof time. But that\\'s because we know how things\\nturned out. In Newton\\'s day the three problems \\nseemed roughly equally promising. No one knew yet\\nwhat the payoff would be for inventing what we\\nnow call physics; if they had, more people would \\nhave been working on it. And alchemy and theology\\nwere still then in the category Marc Andreessen would \\ndescribe as \"huge, if true.\"\\n\\nNewton made three bets. One of them worked. But \\nthey were all risky.\\nNovember 2016', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              " Document(page_content=\"If you're a California voter, there is an important proposition\\non your ballot this year: Proposition 62, which bans the death\\npenalty.\\n\\nWhen I was younger I used to think the debate about the death\\npenalty was about when it's ok to take a human life.  Is it ok\\nto kill a killer?\\n\\nBut that is not the issue here.\\n\\nThe real world does not work like the version I was shown on TV growing up.  The police \\noften arrest the wrong person.\\nDefendants' lawyers are often incompetent.  And prosecutors\\nare often motivated more by publicity than justice.\\n\\nIn the real world,       \\nabout 4% of people sentenced to death\\nare innocent.\\nSo this is not about whether it's ok to kill killers. This\\nis about whether it's ok to kill innocent people.\\n\\nA child could answer that one for you.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              " Document(page_content=\"This year, in California, you have a chance to end this, by\\nvoting yes on Proposition 62. But beware, because there is another \\nproposition, Proposition 66, whose goal is to make it \\neasier to execute people. So yes on 62, no on 66.\\n\\nIt's time.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              " Document(page_content=\"ramen\\nprofitability before Demo Day.  Though it sounds slightly\\nparadoxical, if you want to raise money, the best thing you can do\\nis get yourself to the point where you don't need to.\\n\\nThere are almost two distinct modes of fundraising: one in which\\nfounders who need money knock on doors seeking it, knowing that\\notherwise the company will die or at the very least people will\\nhave to be fired, and one in which founders who don't need money\\ntake some to grow faster than they could merely on their own revenues.\\nTo emphasize the distinction I'm going to name them: type A fundraising\\nis when you don't need money, and type B fundraising is when you\\ndo.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p3.txt'}, lookup_index=0),\n",
              " Document(page_content=\"Inexperienced founders read about famous startups doing what was\\ntype A fundraising, and decide they should raise money too, since\\nthat seems to be how startups work. Except when they raise money\\nthey don't have a clear path to profitability and are thus doing\\ntype B fundraising.  And they are then surprised how difficult and\\nunpleasant it is.\\n\\nOf course not all startups can make it to ramen profitability in a\\nfew months.  And some that don't still manage to have the upper\\nhand over investors, if they have some other advantage like\\nextraordinary growth numbers or exceptionally formidable founders.\\nBut as time passes it gets increasingly difficult to fundraise from\\na position of strength without being profitable.\\n\\n[19]\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p3.txt'}, lookup_index=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key= os.environ['OPENAI_API_KEY'])"
      ],
      "metadata": {
        "id": "xdIXacYN6pv8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "xFE9o4il7Ocd",
        "outputId": "aa0297c8-9875-4eec-e684-7d0d20111b3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:Chroma:Logger created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Chroma using direct local API.\n",
            "Using DuckDB in-memory for database. Data will be transient.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:Chroma:Index not found\n",
            "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n",
            "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = VectorDBQA.from_chain_type(llm = OpenAI(), chain_type = 'stuff', vectorstore = docsearch)"
      ],
      "metadata": {
        "id": "Iq6xjibN9Hks"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'A small delta of novelty is all you\\'ll be able to get most\\n\\nof the time. Which means if you take this route your ideas\\n\\nwill seem a lot like ones that already exist. Sometimes\\n\\nyou\\'ll find you\\'ve merely rediscovered an idea that did\\n\\nalready exist.  But don\\'t be discouraged.  Remember the huge\\n\\nmultiplier that kicks in when you do manage to think of\\n\\nsomething even a little new.\\n\\nCorollary: the more general the ideas you\\'re talking about,\\n\\nthe less you should worry about repeating yourself.?'\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "5oB5UehY-Jsj",
        "outputId": "e0a113bb-2cc2-4982-9186-648e55e809a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:Chroma:time to pre process our knn query: 3.0994415283203125e-06\n",
            "DEBUG:Chroma:time to run knn query: 0.00023317337036132812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The more general the ideas you're talking about, the less you should worry about repeating yourself because a small delta of novelty is all you'll be able to get most of the time. This means that if you take this route, your ideas will seem a lot like ones that already exist and it's possible you've merely rediscovered an idea that already exists. However, don't be discouraged because when you do manage to think of something even a little new, you get a huge multiplier.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
        "query = \"What were there in the Biographies of Newton ?\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "dDiwjjiH_euR",
        "outputId": "16f56e99-c5c9-407a-f2cf-8cef6f2b999d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:Chroma:time to pre process our knn query: 3.5762786865234375e-06\n",
            "DEBUG:Chroma:time to run knn query: 0.00028967857360839844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "dvOl6MpnAxjm",
        "outputId": "4eb12291-b961-48b7-dd33-63f7f7e8c0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What were there in the Biographies of Newton ?',\n",
              " 'result': ' Biographies of Newton focused more on physics than alchemy or theology.',\n",
              " 'source_documents': [Document(page_content='Biographies of Newton, for example, understandably focus\\nmore on physics than alchemy or theology.\\nThe impression we get is that his unerring judgment\\nled him straight to truths no one else had noticed.\\nHow to explain all the time he spent on alchemy\\nand theology?  Well, smart people are often kind of\\ncrazy.\\n\\nBut maybe there is a simpler explanation. Maybe\\nthe smartness and the craziness were not as separate\\nas we think. Physics seems to us a promising thing\\nto work on, and alchemy and theology obvious wastes\\nof time. But that\\'s because we know how things\\nturned out. In Newton\\'s day the three problems \\nseemed roughly equally promising. No one knew yet\\nwhat the payoff would be for inventing what we\\nnow call physics; if they had, more people would \\nhave been working on it. And alchemy and theology\\nwere still then in the category Marc Andreessen would \\ndescribe as \"huge, if true.\"\\n\\nNewton made three bets. One of them worked. But \\nthey were all risky.\\nNovember 2016', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              "  Document(page_content=\"January 2017\\n\\nPeople who are powerful but uncharismatic will tend to be disliked.\\nTheir power makes them a target for criticism that they don't have\\nthe charisma to disarm. That was Hillary Clinton's problem. It also\\ntends to be a problem for any CEO who is more of a builder than a\\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\\nthe best person for the job.\\n\\nI don't think there is any solution to this problem. It's human\\nnature. The best we can do is to recognize that it's happening, and\\nto understand that being a magnet for criticism is sometimes a sign\\nnot that someone is the wrong person for a job, but that they're\\nthe right one.\\nJanuary 2017\\n\\nBecause biographies of famous scientists tend to \\nedit out their mistakes, we underestimate the \\ndegree of risk they were willing to take.\\nAnd because anything a famous scientist did that\\nwasn't a mistake has probably now become the\\nconventional wisdom, those choices don't\\nseem risky either.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              "  Document(page_content='An idea with a small amount of novelty could lead to one\\n\\nwith more. But only if you keep going. So it\\'s doubly\\n\\nimportant not to let yourself be discouraged by people who\\n\\nsay there\\'s not much new about something you\\'ve discovered.\\n\\n\"Not much new\" is a real achievement when you\\'re talking\\n\\nabout the most general ideas. Maybe if you keep going,\\n\\nyou\\'ll discover more.\\n\\nIt\\'s not true that there\\'s nothing new under the sun.  There\\n\\nare some domains where there\\'s almost nothing new.  But\\n\\nthere\\'s a big difference between nothing and almost nothing,\\n\\nwhen it\\'s multiplied by the area under the sun.\\n\\n<b>Thanks</b> to Sam Altman, Patrick Collison, and Jessica\\n\\nLivingston for reading drafts of this.', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              "  Document(page_content=\"A small delta of novelty is all you'll be able to get most\\n\\nof the time. Which means if you take this route your ideas\\n\\nwill seem a lot like ones that already exist. Sometimes\\n\\nyou'll find you've merely rediscovered an idea that did\\n\\nalready exist.  But don't be discouraged.  Remember the huge\\n\\nmultiplier that kicks in when you do manage to think of\\n\\nsomething even a little new.\\n\\nCorollary: the more general the ideas you're talking about,\\n\\nthe less you should worry about repeating yourself.  If you\\n\\nwrite enough, it's inevitable you will.  Your brain is much\\n\\nthe same from year to year and so are the stimuli that hit\\n\\nit. I feel slightly bad when I find I've said something\\n\\nclose to what I've said before, as if I were plagiarizing\\n\\nmyself. But rationally one shouldn't.  You won't say\\n\\nsomething exactly the same way the second time, and that\\n\\nvariation increases the chance you'll get that tiny but\\n\\ncritical delta of novelty.\\n\\nAnd of course, ideas beget ideas.  (That sounds familiar.)\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0)]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['source_documents']"
      ],
      "metadata": {
        "id": "6hMYo9RYAdcO",
        "outputId": "c5b5bbaa-ff1e-4052-84b6-2c2eaf7e6ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Biographies of Newton, for example, understandably focus\\nmore on physics than alchemy or theology.\\nThe impression we get is that his unerring judgment\\nled him straight to truths no one else had noticed.\\nHow to explain all the time he spent on alchemy\\nand theology?  Well, smart people are often kind of\\ncrazy.\\n\\nBut maybe there is a simpler explanation. Maybe\\nthe smartness and the craziness were not as separate\\nas we think. Physics seems to us a promising thing\\nto work on, and alchemy and theology obvious wastes\\nof time. But that\\'s because we know how things\\nturned out. In Newton\\'s day the three problems \\nseemed roughly equally promising. No one knew yet\\nwhat the payoff would be for inventing what we\\nnow call physics; if they had, more people would \\nhave been working on it. And alchemy and theology\\nwere still then in the category Marc Andreessen would \\ndescribe as \"huge, if true.\"\\n\\nNewton made three bets. One of them worked. But \\nthey were all risky.\\nNovember 2016', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p2.txt'}, lookup_index=0),\n",
              " Document(page_content='An idea with a small amount of novelty could lead to one\\n\\nwith more. But only if you keep going. So it\\'s doubly\\n\\nimportant not to let yourself be discouraged by people who\\n\\nsay there\\'s not much new about something you\\'ve discovered.\\n\\n\"Not much new\" is a real achievement when you\\'re talking\\n\\nabout the most general ideas. Maybe if you keep going,\\n\\nyou\\'ll discover more.\\n\\nIt\\'s not true that there\\'s nothing new under the sun.  There\\n\\nare some domains where there\\'s almost nothing new.  But\\n\\nthere\\'s a big difference between nothing and almost nothing,\\n\\nwhen it\\'s multiplied by the area under the sun.\\n\\n<b>Thanks</b> to Sam Altman, Patrick Collison, and Jessica\\n\\nLivingston for reading drafts of this.', lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              " Document(page_content=\"September 2017\\n\\nThe most valuable insights are both general and surprising.\\n\\nF&nbsp;=&nbsp;ma for example. But general and surprising is a hard\\n\\ncombination to achieve. That territory tends to be picked\\n\\nclean, precisely because those insights are so valuable.\\n\\nOrdinarily, the best that people can do is one without the\\n\\nother: either surprising without being general (e.g.\\n\\ngossip), or general without being surprising (e.g.\\n\\nplatitudes).\\n\\nWhere things get interesting is the moderately valuable\\n\\ninsights.  You get those from small additions of whichever\\n\\nquality was missing.  The more common case is a small\\n\\naddition of generality: a piece of gossip that's more than\\n\\njust gossip, because it teaches something interesting about\\n\\nthe world. But another less common approach is to focus on\\n\\nthe most general ideas and see if you can find something new\\n\\nto say about them. Because these start out so general, you\\n\\nonly need a small delta of novelty to produce a useful\\n\\ninsight.\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0),\n",
              " Document(page_content=\"A small delta of novelty is all you'll be able to get most\\n\\nof the time. Which means if you take this route your ideas\\n\\nwill seem a lot like ones that already exist. Sometimes\\n\\nyou'll find you've merely rediscovered an idea that did\\n\\nalready exist.  But don't be discouraged.  Remember the huge\\n\\nmultiplier that kicks in when you do manage to think of\\n\\nsomething even a little new.\\n\\nCorollary: the more general the ideas you're talking about,\\n\\nthe less you should worry about repeating yourself.  If you\\n\\nwrite enough, it's inevitable you will.  Your brain is much\\n\\nthe same from year to year and so are the stimuli that hit\\n\\nit. I feel slightly bad when I find I've said something\\n\\nclose to what I've said before, as if I were plagiarizing\\n\\nmyself. But rationally one shouldn't.  You won't say\\n\\nsomething exactly the same way the second time, and that\\n\\nvariation increases the chance you'll get that tiny but\\n\\ncritical delta of novelty.\\n\\nAnd of course, ideas beget ideas.  (That sounds familiar.)\", lookup_str='', metadata={'source': 'drive/MyDrive/transfer/p_graham_essays/p1.txt'}, lookup_index=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueHIh7E9Al9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}